{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting keras==2.2.4\n",
      "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras==2.2.4) (1.5.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras==2.2.4) (5.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 109.3 MB 132 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.18.5)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.12.3)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 28.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001b[K     |████████████████████████████████| 488 kB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.27.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (47.3.1.post20200622)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.0\n",
      "    Uninstalling tensorboard-2.1.0:\n",
      "      Successfully uninstalled tensorboard-2.1.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4\n",
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers \n",
    "\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D \n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image data argumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_a7065add3d834562bf7e62228951934b = 'https://s3-api.us-geo.objectstorage.softlayer.net'\n",
    "else:\n",
    "    endpoint_a7065add3d834562bf7e62228951934b = 'https://s3-api.us-geo.objectstorage.service.networklayer.com'\n",
    "\n",
    "client_a7065add3d834562bf7e62228951934b = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='rPZ-p0RRWxZBKedxEbuybERq4hIlC6KyAIfENXj4SZL1',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_a7065add3d834562bf7e62228951934b)\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "streaming_body_1 = client_a7065add3d834562bf7e62228951934b.get_object(Bucket='imageclassification-donotdelete-pr-gqtgizzimr2slj', Key='Dataset.zip')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n",
    "file_paths=unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = os.listdir('/home/wsuser/work/Dataset/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading our data and performing data agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 594 images belonging to 6 classes.\n",
      "Found 30 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'/home/wsuser/work/Dataset/train',target_size = (64,64),batch_size = 5, color_mode='grayscale', class_mode = \"categorical\")\n",
    "x_test= test_datagen.flow_from_directory(r'/home/wsuser/work/Dataset/test',target_size = (64,64),batch_size = 5, color_mode = 'grayscale',class_mode = \"categorical\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n"
     ]
    }
   ],
   "source": [
    "print(x_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 99, 1: 99, 2: 99, 3: 99, 4: 99, 5: 99})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train .labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the model\n",
    "# Adding CNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Adding dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=6, activation='softmax')) # softmax for more than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 813,286\n",
      "Trainable params: 813,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "119/119 [==============================] - 8s 66ms/step - loss: 1.4068 - acc: 0.4158 - val_loss: 0.7995 - val_acc: 0.6667\n",
      "Epoch 2/10\n",
      "119/119 [==============================] - 7s 58ms/step - loss: 0.6894 - acc: 0.7222 - val_loss: 0.7428 - val_acc: 0.7000\n",
      "Epoch 3/10\n",
      "119/119 [==============================] - 7s 58ms/step - loss: 0.4567 - acc: 0.8114 - val_loss: 0.5632 - val_acc: 0.8333\n",
      "Epoch 4/10\n",
      "119/119 [==============================] - 7s 55ms/step - loss: 0.3763 - acc: 0.8519 - val_loss: 0.4049 - val_acc: 0.7667\n",
      "Epoch 5/10\n",
      "119/119 [==============================] - 7s 57ms/step - loss: 0.3233 - acc: 0.8771 - val_loss: 0.4402 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "119/119 [==============================] - 7s 56ms/step - loss: 0.2515 - acc: 0.9057 - val_loss: 0.2252 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.2155 - acc: 0.919 - 7s 56ms/step - loss: 0.2175 - acc: 0.9192 - val_loss: 0.2187 - val_acc: 0.9667\n",
      "Epoch 8/10\n",
      "119/119 [==============================] - 7s 56ms/step - loss: 0.1450 - acc: 0.9495 - val_loss: 0.3139 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "119/119 [==============================] - 7s 57ms/step - loss: 0.1606 - acc: 0.9411 - val_loss: 0.1281 - val_acc: 0.9667\n",
      "Epoch 10/10\n",
      "119/119 [==============================] - 7s 56ms/step - loss: 0.1026 - acc: 0.9646 - val_loss: 0.2986 - val_acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f02c155ec90>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " classifier.fit_generator(\n",
    "        generator=x_train,steps_per_epoch = len(x_train),\n",
    "        epochs=10, validation_data=x_test,validation_steps = len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('gesture.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gesture.h5\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf image-classification-model_new.tgz gesture.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mDataset\u001b[0m/\r\n",
      "gesture.h5\r\n",
      "image-classification-model_new.tgz\r\n",
      "model.tar.ga\r\n",
      "model.tar.gc\r\n"
     ]
    }
   ],
   "source": [
    "ls -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already up-to-date: watson-machine-learning-client in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (1.0.391)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (1.13.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: lomond in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from watson-machine-learning-client) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->watson-machine-learning-client) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from boto3->watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from boto3->watson-machine-learning-client) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from boto3->watson-machine-learning-client) (1.16.11)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from lomond->watson-machine-learning-client) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-core==2.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-s3transfer==2.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas->watson-machine-learning-client) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas->watson-machine-learning-client) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas->watson-machine-learning-client) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.11->boto3->watson-machine-learning-client) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials={\"url\":\"https://us-south.ml.cloud.ibm.com\",\n",
    "                \"apikey\":\"GU8qMKqu1lH6gyiwgXBKldXeW1u02OFay1loLjVLGbcJ\"}\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_space_name(client,space_name):\n",
    "    space=client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity'][\"name\"]==space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space UID = 87e990a9-c2f7-438a-9467-1b3f5b5a7076\n"
     ]
    }
   ],
   "source": [
    "space_uid=guid_space_name(client,'imageclassification')\n",
    "print(\"space UID = \"+space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------------------------------  ----\n",
      "NAME                           ASSET_ID                              TYPE\n",
      "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
      "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
      "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
      "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
      "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
      "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
      "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
      "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
      "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
      "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
      "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
      "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
      "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
      "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
      "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
      "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
      "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
      "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
      "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
      "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
      "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
      "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
      "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
      "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
      "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
      "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
      "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
      "spark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\n",
      "tensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\n",
      "spss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\n",
      "pytorch-onnx_1.2-py3.6         692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\n",
      "do_12.9                        75a3a4b0-6aa0-41b3-a618-48b1f56332a6  base\n",
      "spark-mllib_2.3-scala_2.11     7963efe5-bbec-417e-92cf-0574e21b4e8d  base\n",
      "spark-mllib_2.4-py37           7abc992b-b685-532b-a122-a396a3cdbaab  base\n",
      "caffe_1.0-py3.6                7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\n",
      "cuda-py3.6                     82c79ece-4d12-40e6-8787-a7b9e0f62770  base\n",
      "tensorflow_1.15-py3.6-horovod  8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\n",
      "hybrid_0.1                     8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\n",
      "pytorch-onnx_1.3-py3.7         8d5d8a87-a912-54cf-81ec-3914adaa988d  base\n",
      "caffe-ibm_1.0-py3.6            8d863266-7927-4d1e-97d7-56a7f4c0a19b  base\n",
      "spss-modeler_17.1              902d0051-84bd-4af6-ab6b-8f6aa6fdeabb  base\n",
      "do_12.10                       9100fd72-8159-4eb9-8a0b-a87e12eefa36  base\n",
      "do_py3.7                       9447fa8b-2051-4d24-9eef-5acb0e3c59f8  base\n",
      "spark-mllib_3.0-r_3.6          94bb6052-c837-589d-83f1-f4142f219e32  base\n",
      "cuda-py3.7                     9a44990c-1aa1-4c7d-baf8-c4099011741c  base\n",
      "hybrid_0.2                     9b3f9040-9cee-4ead-8d7a-780600f542f7  base\n",
      "autoai-kb_3.3-py3.7            a545cca3-02df-5c61-9e88-998b09dc79af  base\n",
      "autoai-obm_2.0 with Spark 3.0  af10f35f-69fa-5d66-9bf5-acb58434263a  base\n",
      "tensorflow_2.1-py3.7           c4032338-2a40-500a-beef-b01ab2667e27  base\n",
      "autoai-kb_3.0-py3.6            d139f196-e04b-5d8b-9140-9a10ca1fa91a  base\n",
      "-----------------------------  ------------------------------------  ----\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e4429883-c883-42b6-87a8-f419d64088cd'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_space_uid=client.software_specifications.get_uid_by_name(\"default_py3.7\")\n",
    "software_space_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Warnings!! :  Model type keras_2.2.4 is deprecated. We recommend you use a supported model type. See Supported Frameworks https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n"
     ]
    }
   ],
   "source": [
    "model_details = client.repository.store_model(model='image-classification-model_new.tgz',meta_props={\n",
    "    client.repository.ModelMetaNames.NAME:\"Image processing and model building\",\n",
    "    client.repository.ModelMetaNames.TYPE:\"keras_2.2.4\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_space_uid}\n",
    "                                            )\n",
    "model_id = client.repository.get_model_uid(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2199cd47-e0ac-4d9f-991f-ad314f41b7e0'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model content to file: 'model.tar.gb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work/model.tar.gb'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.download(model_id,'model.tar.gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "\n",
    "# Initialization\n",
    "\n",
    "loaded_model = keras.models.load_model('gesture.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "streaming_body_2 = client_a7065add3d834562bf7e62228951934b.get_object(Bucket='imageclassification-donotdelete-pr-gqtgizzimr2slj', Key='3.jpg')['Body']\n",
    "# add missing __iter__ method so pandas accepts body as file-like object\n",
    "if not hasattr(streaming_body_2, \"__iter__\"): streaming_body_2.__iter__ = types.MethodType( __iter__, streaming_body_2 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(streaming_body_2,target_size = (64,64) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=image.img_to_array(img)\n",
    "x =np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# redicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=classifier.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['0','1','2','3','4','5']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
